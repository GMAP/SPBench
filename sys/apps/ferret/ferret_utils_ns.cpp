/** 
 * ************************************************************************  
 *  File  : ferret.hpp
 *
 *  Title : SPBench version of the Ferret application
 *
 *  Author: Adriano Marques Garcia <adriano1mg@gmail.com> 
 *
 *  Date  : July 06, 2021
 *
 * ************************************************************************
**/

/** 
 * Copyright (C) 2007 Princeton University
 *       
 * This file is part of Ferret Toolkit.
 * 
 * Ferret Toolkit is free software; you can redistribute it and/or modify
 * it under the terms of the GNU General Public License as published by
 * the Free Software Foundation; either version 2, or (at your option)
 * any later version.
 * 
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 * 
 * You should have received a copy of the GNU General Public License
 * along with this program; if not, write to the Free Software Foundation,
 * Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301, USA.
**/

#include <ferret_utils_ns.hpp>

namespace spb{
void input_parser(char * argv);

void set_operators_name();
void end_bench();

std::vector<IO_data_struct> IO_data_vec;
std::vector<input_data> input_data_vec;

char *extra_params = "-L 8 - T 20";

struct item_data *file_helper (const char *);
void push_dir(const char *);
void scan(const char *);

struct item_data *file_helper (const char *file)
{
	int r;
	struct item_data *data;

	data = (struct item_data *)malloc(sizeof(struct item_data));
	assert(data != NULL);

	data->first.load.name = strdup(file);

	r = image_read_rgb_hsv(file,
			&data->first.load.width,
			&data->first.load.height,
			&data->first.load.RGB,
			&data->first.load.HSV);
	assert(r == 0);

	return data;
}

void push_dir(const char * dir, path_data &path) {
	int path_len = strlen(path.m_path);
	DIR *pd = NULL;

	strcat(path.m_path, dir);
	pd = opendir(path.m_path);
	if (pd != NULL) {
		strcat(path.m_path, "//");
		path.m_dir_stack.push(pd);
		path.m_path_stack.push(path_len);
	} else {
		path.m_path[path_len] = 0;
	}
}

void scan(const char * dir, path_data &path) {
	path.m_path[0] = 0;
	int ret;
	if (strcmp(dir, ".") == 0) {
		path.m_single_file = NULL;
		push_dir(".", path);
	} else if (strcmp(dir, "..") == 0) {
		path.m_single_file = NULL;
	}
	else {
		struct stat st;
		ret = stat(dir, &st);
		if (ret != 0){
			perror("Error:");
			path.m_single_file = NULL;
		}
		if (S_ISREG(st.st_mode)) {
			path.m_single_file = dir;
		} else if (S_ISDIR(st.st_mode)) {
			path.m_single_file = NULL;
			push_dir(dir, path);
		}
	}
}


void set_operators_name(){
	SPBench::addOperatorName("Source       ");
	SPBench::addOperatorName("Segmentation ");
	SPBench::addOperatorName("Extract      ");
	SPBench::addOperatorName("Vectorization");
	SPBench::addOperatorName("Rank         ");
	SPBench::addOperatorName("Sink         ");
}

inline void usage(std::string name){
	fprintf(stderr, "Usage: %s\n", name.c_str());
	fprintf(stderr, "\t-i\t: \"<db_dir> <table_name> <query_dir> <top_K> <id (optional)>\" (mandatory)\n");
	fprintf(stderr, "\t-b\t: <batch_size_in_number_of_items>\n");
	fprintf(stderr, "\t-B\t: <batch_size_in_milliseconds>\n");
	fprintf(stderr, "\t-F\t: <target_throughput>\n");
	fprintf(stderr, "\t-p\t: Frequency pattern: <pattern,period,min,max>\n");
	fprintf(stderr, "\t-t\t: <number_of_threads>\n");
	fprintf(stderr, "\t-k\t: enable in-memory execution\n");
	fprintf(stderr, "\t-l\t: print average latency results\n");
	fprintf(stderr, "\t-f\t: store individual latency values into a log file\n");
	fprintf(stderr, "\t-m\t: monitors latency, throughput, and CPU and memory usage.\n");
	fprintf(stderr, "\t-x\t: print average throughput results\n");
	fprintf(stderr, "\t-r\t: print memory consumption results generated by UPL library\n");
	fprintf(stderr, "\t-u\t: send a custom argument to be used inside your programm\n");
	fprintf(stderr, "\t-h\t: print this help message\n");
	exit(-1);
}

void input_parser(char * argv){
	input_data new_input;
	new_input.db_dir = strtok (argv," ");
	new_input.table_name = strtok (NULL," ");
	new_input.query_dir = strtok (NULL," ");
	new_input.top_K = atoi(strtok (NULL," "));
	new_input.inputId = strtok(NULL," ");
	input_data_vec.push_back(new_input);
}

void init_bench(int argc, char *argv[]){

	/*if (argc < 5)
	{
		printf("%s <database> <table> <query dir> <top K> <ignored> <n> <out>\n", argv[0]);
		exit(0);
	}*/
	
	SPBench::bench_path = argv[0];

	int opt;
	while ((opt = getopt(argc,argv,"i:t:b:m:B:F:u:klfxrh")) != EOF){
		switch(opt){
			case 'i':
				input_parser(optarg);
				break;
			case 't':
				nthreads = atoi(optarg);
				break;
			case 'b':
				if (atoi(optarg) <= 0)
					throw std::invalid_argument("\n ARGUMENT ERROR (-b <batch_size>) --> Batch size must be an integer value higher than zero!\n");
				SPBench::setBatchSize(atoi(optarg));
				break;
			case 'B':
				if (atof(optarg) <= 0.0)
					throw std::invalid_argument("\n ARGUMENT ERROR (-B <batch_interval>) --> Batch interval must be a value higher than zero!\n");
				SPBench::setBatchInterval(atof(optarg));
			case 'm':
				Metrics::set_monitoring_time_interval(atoi(optarg));
				Metrics::enable_monitoring();
				break;
			case 'F':
				if (atof(optarg) <= 0.0)
					throw std::invalid_argument("\n ARGUMENT ERROR (-F <frequency>) --> Frequency value must be higher than zero!\n");
				SPBench::setFrequency(atof(optarg));
				break;
			case 'k':
				SPBench::enable_memory_source();
				break;
			case 'l':
				Metrics::enable_print_latency();
				break;
			case 'f':
				Metrics::enable_latency_to_file();
				break;
			case 'x':
				Metrics::enable_throughput();
				break;
			case 'r':
				Metrics::enable_upl();
				break;
			case 'u':
				SPBench::setArg(optarg);
				break;
			case 'h':
				usage(argv[0]);
				break;
			case '?': 
				usage(argv[0]);
				break;
			default: 
				std::cout << std::endl; 
				exit(1);
		}
	}
	set_operators_name();
	Metrics::enable_latency();
}

void Source::printStatus(){
	std::cout << "\n - New source added: " << IO_data_vec[sourceId].inputData.inputId << std::endl;

	std::cout << "\n - Workload:" << std::endl;
	std::cout << "      Data base dir: " << IO_data_vec[sourceId].inputData.db_dir << std::endl;
	std::cout << "         Table name: " << IO_data_vec[sourceId].inputData.table_name << std::endl;
	std::cout << "    Query directory: " << IO_data_vec[sourceId].inputData.query_dir << std::endl;
	std::cout << "   Top K candidates: " << IO_data_vec[sourceId].inputData.top_K << std::endl;

	std::cout << "\n - Setup:" << std::endl;
	std::cout << "         Batch size: " << sourceBatchSize << std::endl;
	std::cout << "     Batch interval: " << sourceBatchInterval << std::endl;
	
	if(sourceQueueSize == 0)
		std::cout << "    Queue max. size: 0 (unlimited)" << std::endl;
	else
		std::cout << "    Queue max. size: " << sourceQueueSize << std::endl;

	if(sourceFrequency == 0)
		std::cout << "    Input frequency: 0 (no limit)" << std::endl;
	else
		std::cout << "    Input frequency: " << sourceFrequency << " items per second" << std::endl;

	if(SPBench::memory_source_is_enabled())
		std::cout << "In-memory execution: enabled" << std::endl;
	std::cout << "\n###############################################" << std::endl;
}

void end_bench(){

	// output file writing for in-memory option
	for (auto & element : IO_data_vec){
		if(SPBench::memory_source_is_enabled()){
			unsigned int num_item = 0;
			while(num_item < element.mem_data_vec.size()){
				struct item_data* ret;
				ret = element.mem_data_vec[num_item];
				
				fprintf(element.outFileData.fout, "%s", ret->first.rank.name);
				do {
					cass_size_t __array_foreach_index;
					for (__array_foreach_index = 0; __array_foreach_index < ret->first.rank.result.u.list.len;
							__array_foreach_index++) {
						cass_list_entry_t *p = ret->first.rank.result.u.list.data + __array_foreach_index;
						char *obj = NULL;
						if (p->dist == DBL_MAX) continue;
						cass_map_id_to_dataobj(element.inputData.query_table->map, p->id, &obj);
						assert(obj != NULL);
						fprintf(element.outFileData.fout, "\t%s:%g", obj, p->dist);
					}
				} while(0);

				fprintf(element.outFileData.fout, "\n");

				cass_result_free(&ret->first.rank.result);
				free(ret->first.rank.name);
				free(ret);
				num_item++;
			}
			
			if(!element.mem_data_vec.empty())
				element.mem_data_vec.erase(element.mem_data_vec.begin(), element.mem_data_vec.end());

		} 
		
		element.outFileData.ret_cass = cass_env_close(element.outFileData.env, 0);
		if (element.outFileData.ret_cass != 0) {
			printf("ERROR: %s\n", cass_strerror(element.outFileData.ret_cass));
			exit(0);
		}
		cass_cleanup();
		image_cleanup();
		fclose(element.outFileData.fout);
	}
	compute_metrics();
}

std::mutex source_init_mutex;

void Source::source_op(){

	int rett;
	path_data pathInfo;

	FILE * fout;
	fout = NULL;

	source_init_mutex.lock();
	
	//IO_data_vec[sourceId].outFileData.fout = fopen((out_file_path("outputs") + "_" + getSourceName() + ".out").c_str(), "w");
	fout = fopen((prepareOutFileAt("outputs") + "_" + getSourceName() + ".out").c_str(), "w");

	assert(fout != NULL);

	cass_init();

	IO_data_vec[sourceId].outFileData.ret_cass = cass_env_open(&IO_data_vec[sourceId].outFileData.env, IO_data_vec[sourceId].inputData.db_dir, 0);
	if (IO_data_vec[sourceId].outFileData.ret_cass != 0) {
		printf("ERROR: %s\n", cass_strerror(IO_data_vec[sourceId].outFileData.ret_cass));
		exit(0);
	}

	IO_data_vec[sourceId].inputData.vec_dist_id = cass_reg_lookup(&IO_data_vec[sourceId].outFileData.env->vec_dist, "L2_float");
	assert(IO_data_vec[sourceId].inputData.vec_dist_id >= 0);

	IO_data_vec[sourceId].inputData.vecset_dist_id = cass_reg_lookup(&IO_data_vec[sourceId].outFileData.env->vecset_dist, "emd");
	assert(IO_data_vec[sourceId].inputData.vecset_dist_id >= 0);

	rett = cass_reg_lookup(&IO_data_vec[sourceId].outFileData.env->table, IO_data_vec[sourceId].inputData.table_name);
	IO_data_vec[sourceId].inputData.query_table = (cass_table_t*) cass_reg_get(&IO_data_vec[sourceId].outFileData.env->table, rett);
	IO_data_vec[sourceId].inputData.table = IO_data_vec[sourceId].inputData.query_table;

	rett = IO_data_vec[sourceId].inputData.table->parent_id;
	if (rett >= 0) {
		IO_data_vec[sourceId].inputData.query_table = (cass_table_t*) cass_reg_get(&IO_data_vec[sourceId].outFileData.env->table, rett);
	}

	if (IO_data_vec[sourceId].inputData.query_table != IO_data_vec[sourceId].inputData.table) cass_table_load(IO_data_vec[sourceId].inputData.query_table);

	cass_map_load(IO_data_vec[sourceId].inputData.query_table->map);

	cass_table_load(IO_data_vec[sourceId].inputData.table);

	scan(IO_data_vec[sourceId].inputData.query_dir, pathInfo);

	source_init_mutex.unlock();

	IO_data_vec[sourceId].outFileData.fout = fout;

	bool end_of_input = false;

	// load data to the memory if in-memory is enabled
	if(SPBench::memory_source_is_enabled()){
		while(1){

			struct item_data* ret;
			bool input_found = false;

			if(pathInfo.m_single_file) {
				ret = file_helper(pathInfo.m_single_file);
				pathInfo.m_single_file = NULL;
				input_found = true;
			}

			if(pathInfo.m_dir_stack.empty()) {
				end_of_input = true;
				break;
			}

			while(input_found!=true) {
				DIR *pd = pathInfo.m_dir_stack.top();
				struct dirent *ent = NULL;
				int res = 0;
				struct stat st;
				int path_len = strlen(pathInfo.m_path);

				ent = readdir(pd);
				if (ent == NULL) {
					closedir(pd);
					pathInfo.m_path[pathInfo.m_path_stack.top()] = 0;
					pathInfo.m_path_stack.pop();
					pathInfo.m_dir_stack.pop();
					if(pathInfo.m_dir_stack.empty()) {
						end_of_input = true;
						break;
					}
				}

				if((ent->d_name[0] == '.') && ((ent->d_name[1] == 0) || ((ent->d_name[1] == '.') && (ent->d_name[2] == 0)) ) )
					continue;

				strcat(pathInfo.m_path, ent->d_name);
				res = stat(pathInfo.m_path, &st);
				if (res != 0) {
					perror("Error:");
					end_of_input = true;
					break;
				}
				if (S_ISREG(st.st_mode)) {
					ret = file_helper(pathInfo.m_path);
					pathInfo.m_path[path_len]=0;
					input_found = true;
				} else if (S_ISDIR(st.st_mode)) {
					pathInfo.m_path[path_len]=0;
					push_dir(ent->d_name, pathInfo);
				} else
					pathInfo.m_path[path_len]=0;
			}
		
			if(end_of_input == true) break;

			IO_data_vec[sourceId].mem_data_vec.push_back(ret);
		}
		end_of_input = false;
	}

	// generate items
	unsigned int sourceItemCounter = 0;
	end_of_input = false;
	long source_item_timestamp = current_time_usecs();

	while(1){

		Item item;

		//if last batch included the last item, ends computation
		if(end_of_input == true){
			item.setLastItem();
			sourceQueue.enqueue(item);
			break;
		}

		// frequency control mechanism
		item_frequency_control(source_item_timestamp, sourceFrequency);

		item.timestamp = source_item_timestamp = current_time_usecs();
		unsigned long batch_elapsed_time = source_item_timestamp;
		
		unsigned long latency_op;
		item.timestamp = current_time_usecs();
		if(Metrics::latency_is_enabled()){
			latency_op = current_time_usecs();
		}

		while(1) { //main source loop
		
			// batching management routines
			if(SPBench::getBatchInterval()){
				if(((current_time_usecs() - batch_elapsed_time) / 1000.0) >= SPBench::getBatchInterval()) break;
			} else {
				if(item.batch_size >= SPBench::getBatchSize()) break;
			}
			if(SPBench::getBatchSize() > 1){
				if(item.batch_size >= SPBench::getBatchSize()) break;
			}
			
			if(SPBench::memory_source_is_enabled()){
				if(sourceItemCounter < IO_data_vec[sourceId].mem_data_vec.size()){
					item.item_batch.resize(item.batch_size+1);
					item.item_batch[item.batch_size] = IO_data_vec[sourceId].mem_data_vec[sourceItemCounter];

				} else {
					end_of_input = true;
					break;
				}
			} else {

				struct item_data* ret;

				bool input_found = false;

				if(pathInfo.m_single_file) {
					ret = file_helper(pathInfo.m_single_file);
					pathInfo.m_single_file = NULL;
					input_found = true;
				}

				if(pathInfo.m_dir_stack.empty()) {
					end_of_input = true;
					break;
				}

				while(input_found!=true) {
					DIR *pd = pathInfo.m_dir_stack.top();
					struct dirent *ent = NULL;
					int res = 0;
					struct stat st;
					int path_len = strlen(pathInfo.m_path);

					ent = readdir(pd);
					if (ent == NULL) {
						closedir(pd);
						pathInfo.m_path[pathInfo.m_path_stack.top()] = 0;
						pathInfo.m_path_stack.pop();
						pathInfo.m_dir_stack.pop();
						if(pathInfo.m_dir_stack.empty()) {
							end_of_input = true;
							break;
						}
					}

					if((ent->d_name[0] == '.') && ((ent->d_name[1] == 0) || ((ent->d_name[1] == '.') && (ent->d_name[2] == 0)) ) )
						continue;

					strcat(pathInfo.m_path, ent->d_name);
					res = stat(pathInfo.m_path, &st);
					if (res != 0) {
						perror("Error:");
						end_of_input = true;
						break;
					}
					if (S_ISREG(st.st_mode)) {
						ret = file_helper(pathInfo.m_path);
						pathInfo.m_path[path_len]=0;
						input_found = true;
					} else if (S_ISDIR(st.st_mode)) {
						pathInfo.m_path[path_len]=0;
						push_dir(ent->d_name, pathInfo);
					} else
						pathInfo.m_path[path_len]=0;
				}

				if(end_of_input == true){
					break;
				}

				ret->sourceId = getSourceId();
				item.item_batch.push_back(ret);
			}		
			item.batch_size++;
			sourceItemCounter++;
			item.setNotEmpty();
		}

		//if this batch has size 0, ends computation
		if(item.batch_size == 0){
			item.setLastItem();
			sourceQueue.enqueue(item);
			break;
		}
		
		if(Metrics::latency_is_enabled()){
			item.latency_op.push_back(current_time_usecs() - latency_op);
		}

		// put item in the output queue
		sourceQueue.enqueue(item);

		// Accumulate the total number of sent batches
		metrics_vec[sourceId].global_batch_counter++;

		// Update the total number of sent items
		metrics_vec[sourceId].global_item_counter = sourceItemCounter;
	}

	return;
}


void Sink::op(Item &item){

	if(item.empty())
		return;

	//metrics computation
	volatile unsigned long latency_op;
	if(Metrics::latency_is_enabled()){
		latency_op = current_time_usecs();
	}

	// If in-memory is enabled, do nothing here, the result is already ready on the output vector
	// Else, then retrieve the data from items and write it on the disk
	if(!SPBench::memory_source_is_enabled()){
		unsigned int num_item = 0;
		while(num_item < item.batch_size){ //batch loop
			struct item_data* ret;
			ret = item.item_batch[num_item];

			// Removing the full path of each query image from the output file
			// Removing the varying path allows to run correctness testing using md5 hash
			// Original form: fprintf(IO_data_vec[item.sourceId].outFileData.fout, "%s", ret->first.rank.name);
			std::string aux = ret->first.rank.name;
			std::size_t found = aux.find_last_of("//");
			fprintf(IO_data_vec[item.sourceId].outFileData.fout, "queries/%s", aux.substr(found+1).c_str());
			
			do {
				cass_size_t __array_foreach_index;
				for (__array_foreach_index = 0; __array_foreach_index < ret->first.rank.result.u.list.len;
						__array_foreach_index++) {
					cass_list_entry_t *p = ret->first.rank.result.u.list.data + __array_foreach_index;
					char *obj = NULL;
					if (p->dist == DBL_MAX) continue;
					cass_map_id_to_dataobj(IO_data_vec[item.sourceId].inputData.query_table->map, p->id, &obj);
					assert(obj != NULL);
					fprintf(IO_data_vec[item.sourceId].outFileData.fout, "\t%s:%g", obj, p->dist);
				}
			} while(0);

			fprintf(IO_data_vec[item.sourceId].outFileData.fout, "\n");

			cass_result_free(&ret->first.rank.result);
			free(ret->first.rank.name);
			free(ret);

			num_item++;
			metrics_vec[item.sourceId].items_at_sink_counter++;
		}
	}

	metrics_vec[item.sourceId].batches_at_sink_counter++;

	if(Metrics::monitoring_is_enabled()){
		monitor_metrics(item.timestamp, item.sourceId);
	}
	if(Metrics::latency_is_enabled()){

		double current_time_sink = current_time_usecs();
		item.latency_op.push_back(current_time_sink - latency_op);
		
		volatile unsigned long total_item_latency = (current_time_sink - item.timestamp);
		metrics_vec[item.sourceId].global_latency_acc += total_item_latency; // to compute real time average latency
		
		item_metrics_data latency;
		latency.local_latency = item.latency_op;
		latency.total_latency = total_item_latency;
		latency.item_sink_timestamp = current_time_sink;
		latency.batch_size = item.batch_size;
		metrics_vec[item.sourceId].latency_vector_ns.push_back(latency);
		metrics_vec[item.sourceId].stop_throughput_clock = current_time_sink;
		item.latency_op.clear();
	}
}

} //end of namespace spb