/**
 * ************************************************************************  
 *  File  : person_recognition_utils.cpp
 *
 *  Title : SPBench version of the Person Recognition
 *
 *  Author: Adriano Marques Garcia <adriano1mg@gmail.com> 
 *
 *  Date  : July 06, 2021
 *
 * ************************************************************************
**/

#include <person_recognition_utils.hpp>

namespace spb{

//Globals:
cv::VideoCapture capture;
cv::VideoWriter fw;

cv::Ptr<cv::FaceRecognizer> model;
cv::Size _faceSize;

std::vector<cv::Mat> MemData; //vector to store data in-memory

workload_data input_data;

bool stream_end = false;

void set_operators_name();
void read_training_set(const std::string &, std::vector<cv::Mat> &);
inline void usage(std::string);

void input_parser(char *);

inline void usage(std::string name){
	fprintf(stderr, "Usage: %s\n", name.c_str());
	fprintf(stderr, "\t-i\t: <input_file> (mandatory)\n");
	fprintf(stderr, "\t-b\t: <number_of_itens_per_batch>\n");
	fprintf(stderr, "\t-t\t: <number_of_threads>\n");
	fprintf(stderr, "\t-m\t: read entire input file into memory first\n");
	fprintf(stderr, "\t-l\t: print average latency results\n");
	fprintf(stderr, "\t-f\t: store individual latency values into a file\n");
	fprintf(stderr, "\t-x\t: print average throughput results\n");
	fprintf(stderr, "\t-u\t: print memory consumption results generated by UPL library\n");
	fprintf(stderr, "\t-h\t: print this help message\n");
	exit(-1);
}

void input_parser(char * argv){

	input_data.input_vid = strtok (argv," ");
	input_data.training_list = strtok (NULL," ");
	input_data.cascade_path = strtok (NULL," ");
	input_data.id = strtok(NULL," ");

	if(!file_exists(input_data.input_vid)){
		printf("Invalid input file!\n");
		//printf("Try run: ./app -i <input_file>\n", argv[0]);
		printf("You can use -h to see more options.\n");
		exit(1);
	}
}

void init_bench(int argc, char* argv[]){

	std::string input;
	int opt;
	while ((opt = getopt(argc,argv,"i:t:b:m:F:u:klfxrh")) != EOF){
		switch(opt){
			case 'i':
				input_parser(optarg);
				break;
			case 't':
				nthreads = atoi(optarg);
				break;
			case 'b':
				SPBench::set_batch_size(atoi(optarg));
				break;
			case 'm':
				Metrics::set_monitoring_time_interval(atoi(optarg));
				Metrics::enable_monitoring();
				break;
			case 'F':
				SPBench::set_items_reading_frequency(atoi(optarg));
				SPBench::enable_memory_source();
				break;
			case 'k':
				SPBench::enable_memory_source();
				break;
			case 'l':
				Metrics::enable_print_latency();
				break;
			case 'f':
				Metrics::enable_latency_to_file();
				break;
			case 'x':
				Metrics::enable_throughput();
				break;
			case 'r':
				Metrics::enable_upl();
				break;
			case 'u':
				SPBench::setArg(optarg);
				break;
			case 'h':
				usage(argv[0]);
				break;
			case '?': 
				usage(argv[0]);
				break;
			default: 
				std::cout << std::endl; 
				exit(1);
		}
	}
	SPBench::bench_path = argv[0];

	//string input = argv[1];

	capture.open(input_data.input_vid);

	cv::Size frame_size(static_cast<int>(capture.get(CV_CAP_PROP_FRAME_WIDTH)), static_cast<int>(capture.get(CV_CAP_PROP_FRAME_HEIGHT)));
	//fw.open(strcat(argv[0], "_result.avi"), OUT_FOURCC, OUT_FPS, frame_size, true);
	
	std::string output_file_name = (prepareOutFileAt("outputs") + "_" + input_data.id + ".avi");

	fw.open(output_file_name.c_str(), OUT_FOURCC, OUT_FPS, frame_size, true);

	//fw.open((out_file_path("outputs") + ".avi").c_str(), OUT_FOURCC, OUT_FPS, frame_size, true);
	/** Initializations: **/
	std::vector<cv::Mat> training_set;
	//frameId = 0;
	
	read_training_set(std::string(input_data.training_list), training_set);
	//PersonRecognizer pr(training_set, LBPH_RADIUS, LBPH_NEIGHBORS, LBPH_GRID_X, LBPH_GRID_Y, LBPH_THRESHOLD);

	//all images are faces of the same person, so initialize the same label for all.
	std::vector<int> labels(training_set.size());
	for (std::vector<int>::iterator it = labels.begin(); it != labels.end(); *(it++) = 10);
	_faceSize = cv::Size(training_set[0].size().width, training_set[0].size().height);

	//build recognizer model:
	model = cv::createLBPHFaceRecognizer(LBPH_RADIUS, LBPH_NEIGHBORS, LBPH_GRID_X, LBPH_GRID_Y, LBPH_THRESHOLD);
	model->train(training_set, labels);
	
	//load the input to the memory before the stream region for in-memory execution
	if(SPBench::memory_source_is_enabled()){
		while(1){
			cv::Mat image;
			capture >> image;
			if (image.empty()) break;
			MemData.push_back(image);
		}
	}

	set_operators_name();
}

void set_operators_name(){
	SPBench::addOperatorName("Source   ");
	SPBench::addOperatorName("Detect   ");
	SPBench::addOperatorName("Recognize");
	SPBench::addOperatorName("Sink     ");
}

bool Source::op(Item &item){

	//if last batch included the last item, ends computation
	if(stream_end == true){
		return false;
	}

	volatile unsigned long latency_op;
	item.timestamp = current_time_usecs();
	if(Metrics::latency_is_enabled()){
		latency_op = current_time_usecs();
	}
	while(item.batch_size < SPBench::get_batch_size()){ //batch loop	
		item_data item_data;
		if(SPBench::memory_source_is_enabled()){
			if(Metrics::items_counter < MemData.size()){
				item_data.image_p = &MemData[Metrics::items_counter];
			} else {
				stream_end = true;
				break;
			}
		} else {
			capture >> item_data.image;
			if(item_data.image.empty()){
				stream_end = true;
				break;
			}
		}

		item_data.index = Metrics::items_counter;
		item.item_batch.resize(item.batch_size+1);
		item.item_batch[item.batch_size] = item_data;
		item.batch_size++;
		Metrics::items_counter++;
	}

	//if this batch has size 0, ends computation
	if(item.batch_size == 0){
		return false;
	}
	
	// frequency control mechanism
	SPBench::item_frequency_control(item.timestamp);

	if(Metrics::latency_is_enabled()){
		item.latency_op[0] = (current_time_usecs() - latency_op) ;
	}

	item.batch_index = Metrics::batch_counter;
	Metrics::batch_counter++;	// sent batches
	return true;
}

void Sink::op(Item &item){
	volatile unsigned long latency_op;
	if(Metrics::latency_is_enabled()){
		latency_op = current_time_usecs();
	}	
	
	//when 'in-memory', do nothing here, the result is already ready on the output vector
	//if not in-memory, then retrieve the data from itens and write it on the disk
	if(!SPBench::memory_source_is_enabled()){
		unsigned int num_item = 0;
		while(num_item < item.batch_size){ //batch loop
			fw.write(item.item_batch[num_item].image);
			item.item_batch[num_item].image.release();	
			num_item++;
		}
	}

	Metrics::items_at_sink_counter++;

	if(Metrics::monitoring_is_enabled()){
		Metrics::monitor_metrics(item.timestamp);
	}
	if(Metrics::latency_is_enabled()){
		item.latency_op[3] = (current_time_usecs() - latency_op);

		volatile unsigned long total_item_latency = (current_time_usecs() - item.timestamp);
		Metrics::global_latency_acc += total_item_latency; // to compute real time average latency
		Metrics::global_current_latency = total_item_latency; // to compute real time latency

		auto latency = Metrics::getLatency_t();
		latency.local_latency = item.latency_op;
		latency.local_total = total_item_latency;
		Metrics::latency_vector.push_back(latency);
		item.latency_op.clear();
	}
}

void end_bench(){
	if(SPBench::memory_source_is_enabled()){
		while(!MemData.empty()){
			fw.write(MemData[0]);
			MemData.erase(MemData.begin());
		}
		if(!MemData.empty())
			MemData.erase(MemData.begin(), MemData.end());
	}
}

void read_training_set(const std::string &list_path, std::vector<cv::Mat> &images) {
	std::ifstream file(list_path.c_str());
	std::string path;
	while (getline(file, path)) {
		images.push_back(cv::imread(path, CV_LOAD_IMAGE_GRAYSCALE));
	}
}

} //end of namespace spb